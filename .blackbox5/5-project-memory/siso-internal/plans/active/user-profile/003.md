---
name: Set up Supabase Storage for Avatars
status: open
created: 2026-01-18T08:24:04Z
parallel: false
effort: 2 hours
depends_on: [002]
conflicts_with: []
---

# Task: 003 - Set up Supabase Storage for Avatars

## Specification
Create and configure the `avatars` bucket in Supabase Storage with proper RLS policies to allow users to upload and manage their own avatar images securely.

## Acceptance Criteria
- [ ] `avatars` bucket created in Supabase Storage
- [ ] Bucket is configured as public (images accessible via CDN)
- [ ] RLS policy allows users to upload to their own folder
- [ ] RLS policy allows users to view their own images
- [ ] RLS policy prevents users from accessing others' images
- [ ] File size limits configured (max 5MB)
- [ ] Allowed file types restricted (jpg, png, webp)
- [ ] Upload/download tested successfully
- [ ] Public URL generation works

## Files
- `supabase/storage/avatars/README.md` (new)
- `supabase/migrations/20260118000003_setup_avatars_storage.sql` (new)
- `scripts/test-avatar-storage.ts` (new)
- `.claude/epics/user-profile/003.md` (new)

## Technical Approach

### Step 1: Create Storage Bucket
Via Supabase Dashboard or SQL:
```sql
-- Insert storage bucket
INSERT INTO storage.buckets (id, name, public, file_size_limit, allowed_mime_types)
VALUES (
  'avatars',
  'avatars',
  true,
  5242880, -- 5MB in bytes
  ARRAY['image/jpeg', 'image/png', 'image/webp']
)
ON CONFLICT (id) DO UPDATE
SET
  public = true,
  file_size_limit = 5242880,
  allowed_mime_types = ARRAY['image/jpeg', 'image/png', 'image/webp'];

-- Verify bucket creation
SELECT * FROM storage.buckets WHERE id = 'avatars';
```

### Step 2: Configure RLS Policies for Storage
```sql
-- Enable RLS on storage.objects
ALTER TABLE storage.objects ENABLE ROW LEVEL SECURITY;

-- Policy: Users can upload to their own folder
DROP POLICY IF EXISTS "Users can upload own avatar" ON storage.objects;

CREATE POLICY "Users can upload own avatar"
ON storage.objects FOR INSERT
TO authenticated
WITH CHECK (
  bucket_id = 'avatars'
  AND auth.uid()::text = (storage.foldername(name))[1]
);

-- Policy: Users can view their own avatars
DROP POLICY IF EXISTS "Users can view own avatar" ON storage.objects;

CREATE POLICY "Users can view own avatar"
ON storage.objects FOR SELECT
TO authenticated
USING (
  bucket_id = 'avatars'
  AND auth.uid()::text = (storage.foldername(name))[1]
);

-- Policy: Public can view avatars (for CDN access)
DROP POLICY IF EXISTS "Public can view avatars" ON storage.objects;

CREATE POLICY "Public can view avatars"
ON storage.objects FOR SELECT
TO public
USING (bucket_id = 'avatars');

-- Policy: Users can delete their own avatars
DROP POLICY IF EXISTS "Users can delete own avatar" ON storage.objects;

CREATE POLICY "Users can delete own avatar"
ON storage.objects FOR DELETE
TO authenticated
USING (
  bucket_id = 'avatars'
  AND auth.uid()::text = (storage.foldername(name))[1]
);
```

### Step 3: Create Folder Structure
```typescript
// scripts/create-avatar-folders.ts
import { createClient } from '@supabase/supabase-js'

const supabase = createClient(
  process.env.VITE_SUPABASE_URL!,
  process.env.VITE_SUPABASE_SERVICE_ROLE_KEY! // Use service role for setup
)

async function createAvatarFolders() {
  // This is conceptual - folders are created automatically on upload
  // But we can create a placeholder to ensure bucket is ready

  const { data, error } = await supabase
    .storage
    .from('avatars')
    .upload('.placeholder', new Blob(['placeholder']), {
      upsert: true
    })

  if (error) {
    console.error('Error creating placeholder:', error)
  } else {
    console.log('Avatar bucket ready:', data)
  }
}

createAvatarFolders()
```

### Step 4: Create Test Script
```typescript
// scripts/test-avatar-storage.ts
import { createClient } from '@supabase/supabase-js'
import { readFileSync } from 'fs'

const supabase = createClient(
  process.env.VITE_SUPABASE_URL!,
  process.env.VITE_SUPABASE_ANON_KEY!
)

async function testAvatarStorage() {
  const userId = 'test-user-id'
  const testFile = Buffer.from('test image content')

  // Test 1: Upload avatar
  console.log('Test 1: Uploading avatar...')
  const { data: uploadData, error: uploadError } = await supabase
    .storage
    .from('avatars')
    .upload(`${userId}/avatar.jpg`, testFile, {
      contentType: 'image/jpeg',
      upsert: true
    })

  if (uploadError) {
    console.log('Test 1 - Upload: FAILED', uploadError)
    return
  }
  console.log('Test 1 - Upload: PASSED')

  // Test 2: Get public URL
  console.log('Test 2: Getting public URL...')
  const { data: urlData } = supabase
    .storage
    .from('avatars')
    .getPublicUrl(`${userId}/avatar.jpg`)

  console.log('Test 2 - Public URL:', urlData.publicUrl ? 'PASSED' : 'FAILED')

  // Test 3: List user's avatars
  console.log('Test 3: Listing user avatars...')
  const { data: listData, error: listError } = await supabase
    .storage
    .from('avatars')
    .list(userId, {
      limit: 10
    })

  console.log('Test 3 - List:', listError ? 'FAILED' : 'PASSED', listData)

  // Test 4: Delete avatar
  console.log('Test 4: Deleting avatar...')
  const { error: deleteError } = await supabase
    .storage
    .from('avatars')
    .remove([`${userId}/avatar.jpg`])

  console.log('Test 4 - Delete:', deleteError ? 'FAILED' : 'PASSED')
}

testAvatarStorage()
```

### Step 5: Run Tests
```bash
# Test storage setup
npm run test-avatar-storage
```

## Dependencies
- Task 002 (RLS policies on database should be configured first)

## Conflicts
None

## Testing
```bash
# Test 1: Verify bucket exists
psql $DATABASE_URL -c "SELECT * FROM storage.buckets WHERE id = 'avatars';"

# Test 2: Check bucket policies
psql $DATABASE_URL -c "
SELECT policyname, cmd, qual
FROM pg_policies
WHERE tablename = 'objects'
AND policyname LIKE '%avatar%';
"

# Test 3: Run automated tests
npm run test-avatar-storage

# Test 4: Manual upload test via curl
curl -X POST \
  "${SUPABASE_URL}/storage/v1/object/avatars/test-user/test.jpg" \
  -H "Authorization: Bearer ${ANON_KEY}" \
  -H "Content-Type: image/jpeg" \
  --data-binary @test-image.jpg
```

## Verification
- [ ] Bucket exists in Supabase Storage
- [ ] Bucket is public (CDN accessible)
- [ ] File size limit set to 5MB
- [ ] Allowed MIME types configured
- [ ] Upload policy works (users can upload)
- [ ] View policy works (users can view own)
- [ ] Delete policy works (users can delete own)
- [ ] Public access works (CDN URLs work)
- [ ] Test suite passes
- [ ] Migration committed

## Security Considerations
- File size limits prevent DOS attacks
- MIME type validation prevents malicious uploads
- RLS ensures users can only access their own folder
- Public access is read-only (no anonymous uploads)
- Consider adding virus scanning for production

## Performance Notes
- Supabase Storage uses CDN for fast delivery
- Images are cached automatically
- Consider adding image transformation for different sizes
- Monitor storage usage to avoid cost surprises

## Notes
- Folder structure: `avatars/{user_id}/{filename}`
- Folders are created automatically on first upload
- Use service role key for admin operations
- Consider implementing image optimization later
- Public URLs are signed and expire
