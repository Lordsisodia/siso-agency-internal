# Prompt Pack: Step 03 â€” Competitor Sweep (Adjacent Spaces)

You are Agent 3 of 4 running a parallel competitive research program.

## âœ… Read-first (prevents drift)

Open and follow your plan config:
- `artifacts/feature-research-config.yaml`

If `decisions.target_user_first` or `decisions.license_policy` is still `TBD`, stop and request a decision (use `docs/07-templates/agent-comms/decision-request.md`).

## ğŸ¯ Goal

Cover adjacent spaces that influence what we should build in **admin + ops + core platform**.

Adjacent categories (in scope):

- CMS / page builders / content ops
- Analytics / attribution / heatmaps / session replay
- Experimentation / feature flags
- Customer support / returns / subscriptions (adjacent to admin experience)
- Workflow automation / internal tools (only if they have â€œstealableâ€ admin patterns)

## âœ… Required outputs (write into the plan folder)

- `artifacts/competitor-matrix.md` (adjacent categories only; includes deepened winners)
- `artifacts/competitor-seeds.txt` (pipe-delimited seed list: name|category|website|notes)
- `artifacts/summary.md` (top patterns + top copyable workflows)
- `artifacts/sources.md` (links)

## ğŸ§© Artifact templates (use the seeded structure)

Your plan folder should be scaffolded with a template for `artifacts/competitor-matrix.md`.
Fill it in â€” donâ€™t delete the headings.

Your plan folder should also include a seeded template for:
- `artifacts/summary.md`
- `artifacts/sources.md`

## ğŸ“Œ Non-negotiables (long-run safe)

- Efficiency: breadth-first â†’ deepen only winners.
- Every checkpoint produces a **step file**.
- All human-facing communication uses the short templates:
  - `docs/07-templates/agent-comms/read-aloud-status-update.md`
  - `docs/07-templates/agent-comms/decision-request.md`

## ğŸ§­ Stages (do in order)

### Stage 0 â€” Align (5 minutes)

1) Define what counts as â€œadjacentâ€ vs â€œout of scopeâ€.
2) Define the â€œtransfer testâ€:
   - If a feature/workflow improves an ecommerce admin workflow, itâ€™s in scope.
   - If itâ€™s pure enterprise infra with no admin UX learnings, deprioritize.

### Stage 1 â€” Breadth sweep (45â€“90 minutes)

1) Populate `artifacts/competitor-seeds.txt` with 30â€“60 tools across the adjacent categories.
2) For each, capture:
   - name + category
   - what they sell (1 line)
   - what we can steal (1 line hypothesis)
   - links (homepage + pricing/features/docs)

Write the structured seed lines into:
- `artifacts/competitor-seeds.txt` (pipe-delimited)

Then copy the best 30â€“60 into:
- `artifacts/competitor-matrix.md` (breadth list section)

### Stage 2 â€” Deepen winners (majority of time)

Pick the top ~15 based on:
- clearest reusable patterns
- easiest integration path (vibe coding)

For each winner, extract:
- Notable features (5â€“10 bullets)
- Copyable workflows (2â€“4 step-by-step flows)
- â€œSteal listâ€ (easy / medium / hard)

Use this winner section template (paste per winner into `artifacts/competitor-matrix.md`):

```md
### <Tool name> (adjacent)

- Category:
- Website:
- What they sell:
- Admin/ops transfer insight (why it matters):

Notable features:
- â€¦

Copyable workflows:
1) â€¦
2) â€¦

What we can steal:
- Easy:
- Medium:
- Hard:

Evidence links:
- â€¦
```

### Stage 3 â€” Synthesis (30â€“60 minutes)

Write `artifacts/summary.md` as:

- âœ… Top 10 workflows we should model in our admin (ranked)
- ğŸ§© Top 10 product patterns (ranked)
- ğŸ§ª Top 5 experimentation/analytics learnings (ranked)
- â“ Open questions / assumptions to verify (numbered)

## ğŸ§  Memory rule (required)

```bash
./docs/.blackbox/scripts/new-step.sh --plan docs/.blackbox/agents/.plans/<plan> "Adjacent sweep checkpoint: <what changed>"
```

Compact early if context feels big:

```bash
./docs/.blackbox/scripts/compact-context.sh --plan docs/.blackbox/agents/.plans/<plan>
```

## ğŸ›‘ Stop conditions

Stop and ask for a decision if:
- you canâ€™t apply the â€œtransfer testâ€ reliably
- a category is expanding too broadly (be strict)
